[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "",
    "text": "Translate üåê\nüá¨üáß ¬¶ üá≥üá¥ ¬¶ üá∫üá¶ ¬¶ üá∑üá∫\n\n\n\n\n\n\n\n\nDATE OF BIRTH\n29.08.1997 (28 years old)\n\n\nGENDER\nMale\n\n\nMARITAL STATUS\nSingle\n\n\nNATIONALITY\nUkraine\n\n\nLOCATION\nBj√∏rnafjorden, Norway\n\n\nEDUCATION\nHigher Education\n\n\nJOB SEARCH\nOpen to opportunities"
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "2016 ‚Äì 2020",
    "text": "2016 ‚Äì 2020\n\n\n\nDegree and Major\nBachelor in Computer Science\n\n\nDescription\nInformation Technology\n\n\nEducational Institution\nState Agro-Technological University\n\n\nMode of Study\nFull-time"
  },
  {
    "objectID": "about.html#june-2023-december-2023",
    "href": "about.html#june-2023-december-2023",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "June 2023 ‚Äì December 2023",
    "text": "June 2023 ‚Äì December 2023\n\n\n\nJob Title\nEconomist\n\n\n\n\nCompany\n¬´Melitopol Milk Factory¬ª\n\n\nLocation\nUkraine, Melitopol\n\n\nDuration\n~7 months\n\n\n\n\nPreparation and updating of company balance sheets\nInventory control of finished products and materials\nAnalysis of sales data by stores\nCalculation of production costs\nAutomation and optimization of workflows using Python, R, and SQL to improve efficiency"
  },
  {
    "objectID": "about.html#november-2020-october-2022",
    "href": "about.html#november-2020-october-2022",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "November 2020 ‚Äì October 2022",
    "text": "November 2020 ‚Äì October 2022\n\n\n\nJob Title\nRisk Management Specialist\n\n\n\n\nCompany\n¬´Forward Bank LLC¬ª\n\n\nLocation\nUkraine, Kyiv\n\n\nDuration\n~2 years\n\n\n\n\nPreparation of risk analysis reports, including regular monitoring and deviation identification\nClient control according to internal requirements: blacklist checks, verification in BKI/PTI databases\nDevelopment and optimization of scripts for automated data checks (R/SQL)\nImplementation of new metrics and indicators for risk assessment\nOracle table administration: creation, modification, deletion, and ensuring data integrity\nData cleaning and preparation: removing duplicates and errors, standardizing data format\nData processing for analysis: aggregation, filtering, and creation of slices based on key parameters and metrics"
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "2016 - 2018",
    "text": "2016 - 2018\n\n\n\nJob Title\nTechnical Specialist\n\n\n\n\nCompany\nBand\n\n\nLocation\nUkraine, Kyiv\n\n\nDuration\n~2 years\n\n\n\n\nRemote technical support for users\nInstallation and configuration of software for Windows and Linux\nRenting and managing VPS (VDS) servers\nWorkflow automation"
  },
  {
    "objectID": "about-ua.html",
    "href": "about-ua.html",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "",
    "text": "–ü–µ—Ä–µ–∫–ª–∞–¥ üåê\nüá¨üáß ¬¶ üá≥üá¥ ¬¶ üá∫üá¶ ¬¶ üá∑üá∫\n\n\n\n\n\n\n\n\n–î–ê–¢–ê –ù–ê–†–û–î–ñ–ï–ù–ù–Ø\n29.08.1997 —Ä. (28 —Ä–æ–∫—ñ–≤)\n\n\n–°–¢–ê–¢–¨\n–ß–æ–ª–æ–≤—ñ—á–∞\n\n\n–°–Ü–ú–ï–ô–ù–ò–ô –°–¢–ê–ù\n–ù–µ–æ–¥—Ä—É–∂–µ–Ω–∏–π\n\n\n–ì–†–û–ú–ê–î–Ø–ù–°–¢–í–û\n–£–∫—Ä–∞—ó–Ω–∞\n\n\n–ú–Ü–°–¶–ï–ü–ï–†–ï–ë–£–í–ê–ù–ù–Ø\nBj√∏rnafjorden, –ù–æ—Ä–≤–µ–≥—ñ—è\n\n\n–û–°–í–Ü–¢–ê\n–í–∏—â–∞\n\n\n–ü–û–®–£–ö –†–û–ë–û–¢–ò\n–†–æ–∑–≥–ª—è–¥–∞—é –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó"
  },
  {
    "objectID": "about-ua.html#section",
    "href": "about-ua.html#section",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "2016 ‚Äì 2020",
    "text": "2016 ‚Äì 2020\n\n\n\n–°—Ç—É–ø—ñ–Ω—å —ñ –Ω–∞–ø—Ä—è–º –Ω–∞–≤—á–∞–Ω–Ω—è\n–ë–∞–∫–∞–ª–∞–≤—Ä –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–Ω–∏—Ö –Ω–∞—É–∫\n\n\n–ù–∞–≤—á–∞–ª—å–Ω–∏–π –∑–∞–∫–ª–∞–¥\n–î–µ—Ä–∂–∞–≤–Ω–∏–π –∞–≥—Ä–æ-—Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç\n\n\n–û–ø–∏—Å\n–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó\n\n\n–§–æ—Ä–º–∞ –Ω–∞–≤—á–∞–Ω–Ω—è\n–î–µ–Ω–Ω–∞"
  },
  {
    "objectID": "about-ua.html#—á–µ—Ä–≤–µ–Ω—å-2023-–≥—Ä—É–¥–µ–Ω—å-2023",
    "href": "about-ua.html#—á–µ—Ä–≤–µ–Ω—å-2023-–≥—Ä—É–¥–µ–Ω—å-2023",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "–ß–µ—Ä–≤–µ–Ω—å 2023 ‚Äì –ì—Ä—É–¥–µ–Ω—å 2023",
    "text": "–ß–µ—Ä–≤–µ–Ω—å 2023 ‚Äì –ì—Ä—É–¥–µ–Ω—å 2023\n\n\n\n–ü–æ—Å–∞–¥–∞\n–ï–∫–æ–Ω–æ–º—ñ—Å—Ç\n\n\n\n\n–ö–æ–º–ø–∞–Ω—ñ—è\n¬´–ú–µ–ª—ñ—Ç–æ–ø–æ–ª—å—Å—å–∫–∏–π –º–æ–ª–æ—á–Ω–∏–π –∑–∞–≤–æ–¥¬ª\n\n\n–ú—ñ—Å—Ü–µ–∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è\n–£–∫—Ä–∞—ó–Ω–∞, –ú–µ–ª—ñ—Ç–æ–ø–æ–ª—å\n\n\n–î–æ—Å–≤—ñ–¥ —Ä–æ–±–æ—Ç–∏\n~7 –º—ñ—Å—è—Ü—ñ–≤\n\n\n\n\n–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –±–∞–ª–∞–Ω—Å–æ–≤–æ—ó –∑–≤—ñ—Ç–Ω–æ—Å—Ç—ñ –∫–æ–º–ø–∞–Ω—ñ—ó\n\n–ö–æ–Ω—Ç—Ä–æ–ª—å —Å–∫–ª–∞–¥—Å—å–∫–∏—Ö –∑–∞–ø–∞—Å—ñ–≤ –≥–æ—Ç–æ–≤–æ—ó –ø—Ä–æ–¥—É–∫—Ü—ñ—ó —Ç–∞ –º–∞—Ç–µ—Ä—ñ–∞–ª—ñ–≤\n\n–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –ø—Ä–æ –ø—Ä–æ–¥–∞–∂—ñ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞—Ö\n\n–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å–æ–±—ñ–≤–∞—Ä—Ç–æ—Å—Ç—ñ –ø—Ä–æ–¥—É–∫—Ü—ñ—ó\n\n–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—è —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Python, R —ñ SQL –¥–ª—è –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"
  },
  {
    "objectID": "about-ua.html#–ª–∏—Å—Ç–æ–ø–∞–¥-2020-–∂–æ–≤—Ç–µ–Ω—å-2022",
    "href": "about-ua.html#–ª–∏—Å—Ç–æ–ø–∞–¥-2020-–∂–æ–≤—Ç–µ–Ω—å-2022",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "–õ–∏—Å—Ç–æ–ø–∞–¥ 2020 ‚Äì –ñ–æ–≤—Ç–µ–Ω—å 2022",
    "text": "–õ–∏—Å—Ç–æ–ø–∞–¥ 2020 ‚Äì –ñ–æ–≤—Ç–µ–Ω—å 2022\n\n\n\n–ü–æ—Å–∞–¥–∞\n–§–∞—Ö—ñ–≤–µ—Ü—å –∑ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Ä–∏–∑–∏–∫–∞–º–∏\n\n\n\n\n–ö–æ–º–ø–∞–Ω—ñ—è\n¬´Forward Bank LLC¬ª\n\n\n–ú—ñ—Å—Ü–µ–∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è\n–£–∫—Ä–∞—ó–Ω–∞, –ö–∏—ó–≤\n\n\n–î–æ—Å–≤—ñ–¥ —Ä–æ–±–æ—Ç–∏\n~2 —Ä–æ–∫–∏\n\n\n\n\n–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏—Ö –∑–≤—ñ—Ç—ñ–≤ —ñ–∑ —Ä–∏–∑–∏–∫—ñ–≤, –≤–∫–ª—é—á–∞—é—á–∏ —Ä–µ–≥—É–ª—è—Ä–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —ñ –≤–∏—è–≤–ª–µ–Ω–Ω—è –≤—ñ–¥—Ö–∏–ª–µ–Ω—å\n\n–ö–æ–Ω—Ç—Ä–æ–ª—å –∫–ª—ñ—î–Ω—Ç—ñ–≤ –∑–∞ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ–º–∏ –≤–∏–º–æ–≥–∞–º–∏: –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞ —á–æ—Ä–Ω–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏, –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö —É –±–∞–∑–∞—Ö BKI/PTI\n\n–†–æ–∑—Ä–æ–±–∫–∞ —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Å–∫—Ä–∏–ø—Ç—ñ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–æ–≤–∞–Ω–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –¥–∞–Ω–∏—Ö (R/SQL)\n\n–í–ø—Ä–æ–≤–∞–¥–∂–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫ —ñ –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ —Ä–∏–∑–∏–∫—ñ–≤\n\n–ê–¥–º—ñ–Ω—ñ—Å—Ç—Ä—É–≤–∞–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—å Oracle: —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è, –∑–º—ñ–Ω–∞, –≤–∏–¥–∞–ª–µ–Ω–Ω—è –π –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è —Ü—ñ–ª—ñ—Å–Ω–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö\n\n–û—á–∏—â–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö: –≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ —ñ –ø–æ–º–∏–ª–æ–∫, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –¥–∞–Ω–∏—Ö\n\n–û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É: –∞–≥—Ä–µ–≥–∞—Ü—ñ—è, —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑—Ä—ñ–∑—ñ–≤ –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –π –º–µ—Ç—Ä–∏–∫–∞–º–∏"
  },
  {
    "objectID": "about-ua.html#section-1",
    "href": "about-ua.html#section-1",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "2016 - 2018",
    "text": "2016 - 2018\n\n\n\n–ü–æ—Å–∞–¥–∞\n–¢–µ—Ö–Ω—ñ—á–Ω–∏–π —Å–ø–µ—Ü—ñ–∞–ª—ñ—Å—Ç\n\n\n\n\n–ö–æ–º–ø–∞–Ω—ñ—è\nBand\n\n\n–ú—ñ—Å—Ü–µ–∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è\n–£–∫—Ä–∞—ó–Ω–∞, –ö–∏—ó–≤\n\n\n–î–æ—Å–≤—ñ–¥ —Ä–æ–±–æ—Ç–∏\n~2 —Ä–æ–∫–∏\n\n\n\n\n–í—ñ–¥–¥–∞–ª–µ–Ω–∞ —Ç–µ—Ö–Ω—ñ—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤\n\n–í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–æ–≥—Ä–∞–º–Ω–æ–≥–æ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è –¥–ª—è Windows —ñ Linux\n\n–û—Ä–µ–Ω–¥–∞ —Ç–∞ –∫–µ—Ä—É–≤–∞–Ω–Ω—è VPS (VDS) —Å–µ—Ä–≤–µ—Ä–∞–º–∏\n\n–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—è —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the website!",
    "section": "",
    "text": "On the site you can see my portfolio click\nAbout me click\nDon‚Äôt be shy about contacting me on the links below!\n\n \n  \n   \n  \n    \n     Telegram\n  \n  \n    \n     Email"
  },
  {
    "objectID": "index.html#portfolio",
    "href": "index.html#portfolio",
    "title": "Welcome to the website!",
    "section": "Portfolio",
    "text": "Portfolio\nFollow the link to view publications in the portfolio\n\n\n\n\n\n\n\n\nBinol vs Olive\n\n\n\n14 Dec 2024\n\n\n\n\n\n\n\n\n\n\n\nOCR Reader\n\n\n\n06 Dec 2024\n\n\n\n\n\n\n\n\n\n\n\nWeb Scraping\n\n\n\n20 Jul 2024\n\n\n\n\n\n\n\n\n\n\n\nBeautiful export to Excel (xlsx)\n\n\n\n10 Jul 2024\n\n\n\n\n\n\n\n\n\n\n\nCheese sales\n\n\n\n06 Jul 2024\n\n\n\n\n\n\n\n\n\n\n\nRevenue segment\n\n\n\n03 Jul 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/portfolio/posts/cheese-sales.html",
    "href": "content/portfolio/posts/cheese-sales.html",
    "title": "Cheese sales",
    "section": "",
    "text": "library(plotrix)\nlibrary(dplyr)\n\ndf &lt;- tibble(\n  NM = c(\"Cheddar\", \"Mozzarella\", \"Brie\", \"Parmesan\", \"Gouda\"),\n  SUM = c(279158, 231399, 606614, 586469, 267434)\n) %&gt;% mutate(PROC = round((SUM / summarise(.,sum(SUM)) %&gt;% as.double())*100,1) %&gt;% paste0('%'))\nExample of a 3D Pie Chart using the plotrix library\npie3D(df$SUM, mar = rep(1,4),\n      col = hcl.colors(length(df$NM), \"Heat 2\"),\n      labels = paste0(df$NM, '\\n',round(df$SUM/1000), ' (', df$PROC, ')'),\n      main = \"Cheese sales\",\n      height=0.1,\n      radius=0.8,\n      labelcex = 1,\n      explode = 0.1)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/posts/revenue-segment.html",
    "href": "content/portfolio/posts/revenue-segment.html",
    "title": "Revenue segment",
    "section": "",
    "text": "In the R language ecosystem, there is a package WebR which allows creating a pie chart like this\n\n\n\n\n\n\n\n\n\n\n\n\nPlotly is a universal framework, available both in Python and R. It allows you to create an interactive pie chart in just a couple of lines of code."
  },
  {
    "objectID": "content/portfolio/posts/revenue-segment.html#r",
    "href": "content/portfolio/posts/revenue-segment.html#r",
    "title": "Revenue segment",
    "section": "",
    "text": "In the R language ecosystem, there is a package WebR which allows creating a pie chart like this"
  },
  {
    "objectID": "content/portfolio/posts/revenue-segment.html#python",
    "href": "content/portfolio/posts/revenue-segment.html#python",
    "title": "Revenue segment",
    "section": "",
    "text": "Plotly is a universal framework, available both in Python and R. It allows you to create an interactive pie chart in just a couple of lines of code."
  },
  {
    "objectID": "content/portfolio/posts/sales_report.html",
    "href": "content/portfolio/posts/sales_report.html",
    "title": "Sales Report",
    "section": "",
    "text": "Binol stores with an area of up to 15m¬≤\nThe presented chart shows the month-by-month sales dynamics. The data indicates that sales volumes in such outlets experience significant fluctuations throughout the year.\n\n\n\n\n\n\nNoteNote\n\n\n\nData for the store 57/9 Kirova Street is unavailable due to its closure.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinol stores with an area of 15m¬≤ or more\n\n\n\n\n\n\n\n\n\n\n\n\nTotal by months\nThe total revenue from the sale of Binol and Olive flowers.\n\n\n\n\n\n\nNoteNote\n\n\n\nThe revenue from Olive was deducted from the total sales of the stores. That is, the Binol figures also include third-party products (warehouse goods).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/index.html",
    "href": "content/portfolio/index.html",
    "title": "Portfolio",
    "section": "",
    "text": "The page contains visual and text examples of interesting results.\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nWeb Scraping\n\n12 min\n\n\nPython\n\nWeb-Scraping\n\n\n\n\n20 July 2024\n\n\n\n\n\n\n\n\n\n\n\nSales Report\n\n5 min\n\n\nR\n\nGraphs\n\n\n\n\n01 July 2024\n\n\n\n\n\n\n\n\n\n\n\nRevenue segment\n\n1 min\n\n\nR\n\nPython\n\nGraphs\n\n\n\n\n03 July 2024\n\n\n\n\n\n\n\n\n\n\n\nOCR Reader\n\n2 min\n\n\nPython\n\nOCR\n\nEasyOCR\n\n\n\n\n06 December 2024\n\n\n\n\n\n\n\n\n\n\n\nCheese sales\n\n1 min\n\n\nR\n\nGraphs\n\n\n\n\n06 July 2024\n\n\n\n\n\n\n\n\n\n\n\nBinol vs Olive\n\n4 min\n\n\nPython\n\nSQLite\n\n\n\n\n14 December 2024\n\n\n\n\n\n\n\n\n\n\n\nBeautiful export to Excel (xlsx)\n\n4 min\n\n\nR\n\nxlsx\n\nExcel\n\n\n\n\n10 July 2024\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/posts/web-scraping.html",
    "href": "content/portfolio/posts/web-scraping.html",
    "title": "Web Scraping",
    "section": "",
    "text": "This code allows you to parse information about vacancies on hh.ru It scans the home page, finds vacancies, follows links to vacancies and collects the specified data\n\nImport and settings\nThe main libraries for parsing are: 1. requests- makes a request to the site and receives data 2. bs4(BeautifulSoup) - parses the result of the request requests\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport polars as pl\nimport re\nimport xlsxwriter\nimport time\n\n1df = pl.DataFrame({\n    \"URL\": pl.Series([], dtype=pl.Utf8),\n    \"–í–∞–∫–∞–Ω—Å–∏—è\": pl.Series([], dtype=pl.Utf8),\n    \"–ó–∞—Ä–ø–ª–∞—Ç–∞\": pl.Series([], dtype=pl.Int64)\n    \"Keyword\": pl.Series([], dtype=pl.Utf8),\n    \"Tags\": pl.Series([], dtype=pl.Utf8)\n})\n\n2query = \"excel\"\n\nstart_url = \"https://hh.ru/search/vacancy?experience=between1And3\" \\\n    \"&order_by=publication_time&ored_clusters=true\" \\\n    f\"&schedule=remote&text={query}&search_period=7\"\n\n3url = start_url\n\n4  headers = {\n      \"User-Agent\": \"Mozilla/5.0 (Windows NT 11.0; Win64; x64)\" \\\n        \"AppleWebKit/538.33 (KHTML, like Gecko) Chrome/98.0.4472.124 Safari/537.36\",\n      \"Accept-Language\": \"ru-RU,ru;q=0.9\",\n      \"Accept-Encoding\": \"gzip, deflate, br\",\n      \"Connection\": \"keep-alive\",\n      \"Upgrade-Insecure-Requests\": \"1\"\n  }\n\n5  keywords = [\"BPMN\", \"Jira\"]\n\n\n1\n\ncreate an empty table, the found information about vacancies will be added to this table\n\n2\n\nstart page of the request, this line takes into account the specified filters on hh, that is, you can go to hh, specify the search criteria, select filters, and then copy the link and paste it into the script\n\n3\n\nthis link serves as the main one for the transition, to go to the second page you need to add page=page numberto the link, I use the code url=f'{start_url}&page={p}' which has a page constant start_urld, and concatenation depending on the iteration of the loop\n\n4\n\nthese settings are needed when requesting requests.get(), to simulate that the user makes a request for the page, when the site requests data, we provide him with data from this list\n\n5\n\nkeywords that the script will search for on the vacancy pages\n\n\n\n\n\n\nChecking the received page (job vacancy)\nWhen requesting a page, there are cases where an incomplete page is received, missing some data This function checks for the presence of data, and if it‚Äôs incomplete, it re-requests the page\n\ndef check_correctly(url):\n1     for i in range(9):\n2          response = requests.get(url, headers=headers)\n3          soup = BeautifulSoup(response.text, 'html.parser')\n\n4          header = soup.find('div', {'class': 'vacancy-title'})\n5          if header:\n6               visit_and_check(url, soup, response)\n               break\n\n\n1\n\nIf the data is incomplete, we repeat the request\n\n2\n\nThe request to retrieve data from the website, url - the link to the data being requested, headers - this is the user-agent created earlier\n\n3\n\nParse the received object (which now contains the ‚Äúroughly speaking‚Äù HTML page), which can be parsed. The advantage is that during testing, no request is made to the website\n\n4\n\nLook for the div class named vacancy-title\n\n5\n\nCheck the header variable (why? Read the header description) to confirm if we received the complete page\n\n6\n\nCall the function and pass url - the link, soup - the local HTML, response - for searching words across the entire page\n\n\n\n\n\n\nScanning the job vacancy\nThis function extracts the necessary data from the page\n\ndef visit_and_check(url, soup, response):\n1  global df\n\n2  fkeys = []\n\n3  for keyword in keywords:\n4      if keyword in response.text:\n5        fkeys.append(keyword)\n  # Finding tags (skills) at the bottom of the page\n6  skill_elements = soup.find_all('li', {'data-qa': 'skills-element'})\n  skills = [li.find('div', class_=re.compile(r'magritte-tag__label')).text for li in skill_elements]\n\n7  header = soup.find('div', {'class': 'vacancy-title'})\n8  title = header.find('h1').text\n\n9  salary_str = header.find('span', {'data-qa': 'vacancy-salary-compensation-type-net'})\n  if salary_str:\n    # Find the first number in a string using a regular expression\n      match = re.search(r'\\d+', salary_str.text.replace('\\xa0', ''))\n      if match:\n        salary = int(match.group())\n      else:\n        salary = None\n  else:\n    salary = None\n\n10  df = df.vstack(pl.DataFrame({\n    \"URL\": [url],\n    \"–í–∞–∫–∞–Ω—Å–∏—è\" : [title],\n    \"–ó–∞—Ä–ø–ª–∞—Ç–∞\" : [salary],\n    \"Keyword\": [', '.join(fkeys)],\n    \"Tags\": [', '.join(skills)]}))\n\n\n1\n\nThis line is needed because of namespaces. The function is called for each job vacancy, and the result of the extracted data needs to be saved in a table. (After the function exits, all objects created inside it are deleted). Therefore, the table is created outside the function, globally, and this line is necessary to access the global table\n\n2\n\nThis list will contain the words found on the page (the list of words is specified in the keywords variable)\n\n3\n\nThe search for the keys specified in keywords happens here, with each keyword being processed one at a time\n\n4\n\nThe search for the key (word) is performed on the response.text object, which is the text returned by the website request\n\n5\n\nIf a keyword is found on the page, it is added to the empty list fkeys (which was created earlier)\n\n6\n\nWe search for the necessary data in the local HTML, which we parsed. In this case, we are looking for tags in the bottom part of the page\n\n7\n\nExtract the header\n\n8\n\nGet the job title\n\n9\n\nGet the salary rate (specified salary) Note: Some vacancies do not specify a salary, and there are cases where a salary range from‚Ä¶to is provided. These cases are handled below:\n\n10\n\nSave the extracted data into the table\n\n\n\n\n\n\nPage navigation and link search\nThis loop scans the main pages (where job vacancies are located), depending on the iteration, it navigates through pages 2, 3, 4‚Ä¶ on the website\n\n1for p in range(9):\n    if p &gt; 0:\n2        url = f'{start_url}&page={p}'\n        print(f\"--- Page {p} --- --- ---\")\n\n    # Searching for all links inside h2 tags\n3    for i in range(9):\n4        time.sleep(3)\n        print(f\"--- --- --- Iteration {i}\")\n5        response = requests.get(url, headers=headers)\n6        soup = BeautifulSoup(response.text, 'html.parser')\n7        if soup.find_all('h2'):\n            for h2 in soup.find_all('h2'):\n                for a in h2.find_all('a', href=True):\n                    absolute_url = requests.compat.urljoin(url, a['href'])\n8                    check_correctly(absolute_url)\n9            break\n\n\n1\n\nSpecify the number of main pages (where job vacancies are located) to scan\n\n2\n\nIf this is not the first iteration of the loop, add ‚Äúpage‚Äù and the page number (the current iteration number) to the URL\n\n3\n\nSometimes hh.ru returns an incomplete page, so in this loop, we check the validity of the received page. If it‚Äôs incomplete, we repeat the request until a complete page is obtained or until the number in the range() function is reached\n\n4\n\nBefore each new request, wait a little to avoid DDOSing the website. The goal is to gather data, simulating a simple navigation\n\n5\n\nThe request to retrieve data from the website, url - the link to the data being requested, headers - this is the user-agent that was created earlier\n\n6\n\nParse the received object (which now contains the ‚Äúroughly speaking‚Äù HTML page), which can be parsed. The advantage is that during testing, no request is made to the website\n\n7\n\nCheck the received page. If it‚Äôs incomplete, make another request (proceed to the next iteration)\n\n8\n\nPass the job vacancy link to the checking variable\n\n9\n\nAt this stage, when we reach if soup.find_all('h2'), it means we have obtained the full link to the page, so no new request is needed for the same link\n\n\n\n\n\n\nSave\nSave the result to an xlsx file\n1wb = xlsxwriter.Workbook('Output.xlsx')\n2ws = wb.add_worksheet('DF')\n\n3df.write_excel(\n    workbook=wb,\n    worksheet='DF',\n    position=\"A1\",\n    table_style=\"Table Style Medium 3\",\n    dtype_formats={pl.Date: \"mm/dd/yyyy\"},\n    column_totals={\"score\": \"average\"},\n    float_precision=1,\n    autofit=True,\n)\n\n\n4ws.set_column('A:A', 10)\nws.set_column('B:B', 40)\nws.set_column('C:C', 10)\nws.set_column('D:D', 20)\nws.set_column('E:E', 90)\n\n5wb.close()\n\n1\n\nCreate a workbook object\n\n2\n\nCreate a sheet\n\n3\n\nInsert the table into the xlsx sheet and specify the column formats\n\n4\n\nSet the width of the columns\n\n5\n\nClose the xlsx file\n\n\n\n\nResult\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/posts/sales-binol-olive.html",
    "href": "content/portfolio/posts/sales-binol-olive.html",
    "title": "Binol vs Olive",
    "section": "",
    "text": "Binol and Olive is concurire market for buys a flowers\n\nLibrary\n\nfrom sqlalchemy import create_engine\nimport duckdb as db\nimport polars as pl\n\nfrom matplotlib.ticker import FuncFormatter\nimport matplotlib.dates as mdates\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom locale import setlocale, LC_TIME\n\n\n\nGet data asdasdasd\n\ncon = db.connect(\"~/Documents/kbase/local.db\")\n\ndf = con.execute(\"\"\"\n  select * from portfolio.salles_binol_olivia\n  where Shops in ('Washington 24', 'Pine 3', 'Cedar 19a', 'Park Avenue 12', 'King Street 25', 'Victoria 38/4')\n\"\"\").pl().with_columns(\n    pl.col('DT').str.to_date(format='%Y-%m-%d')\n  )\n\n\n\nAgregate table\n\nsns.set_theme()\n\ndf_melted = df.melt(id_vars=[\"DT\", \"Shops\"], value_vars=[\"Binol\", \"Olive\"],\n                    variable_name=\"Product\", value_name=\"Value\")\n\ng = sns.FacetGrid(df_melted,\n                  col='Shops',\n                  hue='Product',        # coloring with a new color\n                  col_wrap=3,           # number of plots displayed in one row\n                  sharey=False,         # y-axis shared across all plots\n                  sharex=False,         # x-axis shared across all plots\n                  height=4)             # height\n\ng = g.map(sns.lineplot, 'DT', 'Value', marker='o', markersize=4)\n\n# Apply formatting function to the Y-axis of each subplot\nfor ax in g.axes.flat:\n    # Increase the maximum Y-axis value by 10%\n    ylim = ax.get_ylim()\n    ax.set_ylim((ylim[0], ylim[1] * 1.1))\n\n    # Draw trend lines for each line in ax.lines\n    for line in ax.lines:\n        sns.regplot(\n            x=line.get_xdata(), y=line.get_ydata(), ax=ax,\n            scatter=False,         # No markers (only trend line)\n            color='gray',          # Set line color to gray\n            ci=None,               # No confidence interval shading\n            line_kws={'linestyle': '--'}  # Dashed line\n        )\n    # Format X-axis labels\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n\n# Text annotation function\ndef f(x, y, **kwargs):\n    ax = plt.gca()  # Get current axis\n    for i in range(len(x)):\n        ax.annotate(f\"{y.values[i]:.1f}\", xy=(x.values[i], y.values[i]), fontsize=8,\n                    xytext=(0, 10), textcoords=\"offset points\",\n                    color=\"black\",  # Set color same as line color\n                    bbox=dict(boxstyle=\"round\", ec=\"none\", fc=\"gray\", alpha=0.3, pad=0.3),\n                    va=\"center\", ha=\"center\")\n\ng.map(f, 'DT', 'Value')\n\ng.fig.subplots_adjust(top=.9)         # space for the suptitle from the plot\ng.fig.suptitle('Salles')              # title of the plot\n\ng.add_legend(title=\"Product\")\nsns.move_legend(\n    g, \"center\", bbox_to_anchor=(.5, 1), ncol=5, title=None, frameon=False,\n)\n\n# specify X/Y axis labels\ng.set_axis_labels(\"Date\", \"Amount\")\n\n# set the title of each subplot based on the data table\ng.set_titles(\"{col_name}\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/posts/export-to-xlsx.html",
    "href": "content/portfolio/posts/export-to-xlsx.html",
    "title": "Beautiful export to Excel (xlsx)",
    "section": "",
    "text": "NoteNote\n\n\n\nThis article briefly describes the functions of the openxlsx package. Below is an example of the interaction of functions and the final result of exporting a table from R ‚Üí xlsx\n\n\n\nLibraryes and styles\nlibrary(openxlsx)\n\n## --- Colors\ngray   &lt;- createStyle(fgFill = '#d9d9d9')\ngreen  &lt;- createStyle(fgFill = '#c6e0b4')\nred    &lt;- createStyle(fgFill = '#f9a1a1')\nblue   &lt;- createStyle(fgFill = '#bdd7ee')\nyellow &lt;- createStyle(fgFill = '#ffe699')\nros    &lt;- createStyle(fgFill = '#fce4d6')\nborder &lt;- createStyle(fgFill = '#333333')\n\n## --- Styles\nst_bord &lt;- createStyle(numFmt = \"#,##0\",\n                       border = 'TopBottomLeftRight',borderColour = '#cccccc')\nst_head &lt;- createStyle(textDecoration = \"bold\", halign = \"center\",\n                       border = 'TopBottomLeftRight',borderColour = border)\nst_bot  &lt;- createStyle(textDecoration = 'bold',border = \"top\",\n                       borderColour = border,borderStyle = \"medium\")\nst_name &lt;- createStyle(halign = \"center\", textDecoration = 'bold',\n                       fontSize = 16, border = 'TopBottomLeftRight',\n                       borderColour = border, borderStyle = 'medium')\nst_bold &lt;- createStyle(textDecoration = 'bold',border = \"left\",\n                       borderColour = border,borderStyle = \"medium\")\n\n\nWorkbook and Options\nWe create a workbook (an object in RAM) and a sheet in this workbook named Sales, to which we apply several options: - orientation = ‚Äòportrait‚Äô - specifies the paper orientation (an option for printing on paper) - pageSetup ‚Äì for page margin (helps fit more information on the page when printing on paper)\n## Create a book\nwb &lt;- createWorkbook()\n\n## Adding a Sheet to the xlsx Workbook\naddWorksheet(wb, sheetName = \"Sales\", orientation = 'portrait', gridLines = FALSE)\n\n## Setting Margins\npageSetup(wb, \"Sales\", left = 0.25, top = 0.25, right = 0.25,bottom = 0.25)\n\n\nWriting and Customization\n## Writing Data to the xlsx Sheet\nwriteData(wb, 'Sales', \"Sales\")\n\n## Merging Cells\n1mergeCells(wb, sheet = \"Sales\", cols = 1:length(fin_sales), rows = 1)\n\n2addStyle(wb, 'Sales', st_name, 1, 1:length(fin_sales), stack = TRUE)\n\nwriteData(wb, 'Sales', fin_sales, startRow = 3)\naddStyle(wb, 'Sales', st_head, 3, 1:length(fin_sales),\n         gridExpand = TRUE, stack = TRUE)\n\n1\n\nmerges cells (the range of merged cells is determined automatically)  cols = 1:length(fin_sales)\n\n2\n\napplies the ‚Äúst_name‚Äù style to the specified range\n\n\n## Set Column Widths\n1setColWidths(wb, \"Sales\", cols = 1, widths = 25)\n\naddStyle(wb, 'Sales', st_bord, 4:(nrow(fin_sales)+3),\n         1:length(fin_sales), stack = TRUE, gridExpand = TRUE)\n\n## Apply the st_bot Style to Cells in the Column with Data\naddStyle(wb, 'Sales', st_bot, (which(!is.na(temp_sales$PROC))+3),\n         1:length(temp_sales), stack = TRUE, gridExpand = TRUE)\n\naddStyle(wb, 'Sales', st_bot, nrow(fin_sales)+3, 1:length(fin_sales), stack = TRUE)\naddStyle(wb, 'Sales', createStyle(halign = \"center\"),\n         3:(nrow(fin_sales)+3), length(fin_sales), stack = TRUE, gridExpand = TRUE)\nsetColWidths(wb, \"Sales\", cols = length(fin_sales), widths = 18)\naddStyle(wb, 'Sales', gray, 3, 1, stack = TRUE)\naddStyle(wb, 'Sales', ros, 3, c(2,3), stack = TRUE, gridExpand = TRUE)\naddStyle(wb, 'Sales', green, 3, 4, stack = TRUE)\naddStyle(wb, 'Sales', blue, 3, 5, stack = TRUE)\naddStyle(wb, 'Sales', yellow, 3, 6, stack = TRUE)\n\n1\n\nsetColWidths - sets the width of the column\n\n\n\n\nResult\n\n\n\nConclusion\nThis method of saving to xlsx is, on one hand, ‚Äúverbose,‚Äù but on the other hand, it is very flexible in customization, allowing you to write/apply styles down to the individual cell.\nIf a similar report is generated regularly, where only the data is updated, this approach makes sense. In the long term, it will pay off in subsequent iterations of report generation.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/portfolio/posts/OCR-tool.html#get-img-from-clipboard",
    "href": "content/portfolio/posts/OCR-tool.html#get-img-from-clipboard",
    "title": "OCR Reader",
    "section": "Get img from clipboard",
    "text": "Get img from clipboard\nFunction for get screenshot from clipboard\ndef get_image_from_clipboard():\n1    result = subprocess.run(['xclip', '-selection', 'clipboard', '-t', 'image/png', '-o'], stdout=subprocess.PIPE)\n\n2    if result.returncode != 0:\n        raise Exception(\"Can't get screenshot\")\n\n    return io.BytesIO(result.stdout)\n\n1\n\nGet screenshot from clipboard\n\n2\n\nException"
  },
  {
    "objectID": "content/portfolio/posts/OCR-tool.html#copy-result-into-clipboard",
    "href": "content/portfolio/posts/OCR-tool.html#copy-result-into-clipboard",
    "title": "OCR Reader",
    "section": "Copy result into clipboard",
    "text": "Copy result into clipboard\nThe func for copy OCR result in clipboard\ndef copy_text_to_clipboard(text):\n    subprocess.run(['xclip', '-selection', 'clipboard'], input=text.encode(), check=True)"
  },
  {
    "objectID": "about-ru.html",
    "href": "about-ru.html",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "",
    "text": "–ü–µ—Ä–µ–≤–æ–¥ üåê\nüá¨üáß ¬¶ üá≥üá¥ ¬¶ üá∫üá¶ ¬¶ üá∑üá∫\n\n\n\n\n\n\n\n\n–î–ê–¢–ê –†–û–ñ–î–ï–ù–ò–Ø\n29.08.1997 –≥. (28 –ª–µ—Ç)\n\n\n–ü–û–õ\n–ú—É–∂—Å–∫–æ–π\n\n\n–°–ï–ú–ï–ô–ù–û–ï –ü–û–õ–û–ñ–ï–ù–ò–ï\n–•–æ–ª–æ—Å—Ç\n\n\n–ì–†–ê–ñ–î–ê–ù–°–¢–í–û\n–£–∫—Ä–∞–∏–Ω–∞\n\n\n–ú–ï–°–¢–û–ù–ê–•–û–ñ–î–ï–ù–ò–ï\nBj√∏rnafjorden, –ù–æ—Ä–≤–µ–≥–∏—è\n\n\n–û–ë–†–ê–ó–û–í–ê–ù–ò–ï\n–í—ã—Å—à–µ–µ\n\n\n–ü–û–ò–°–ö –†–ê–ë–û–¢–´\n–†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"
  },
  {
    "objectID": "about-ru.html#section",
    "href": "about-ru.html#section",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "2016 ‚Äì 2020",
    "text": "2016 ‚Äì 2020\n\n\n\n\n\n\n\n–°—Ç–µ–ø–µ–Ω—å –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è\n–ë–∞–∫–∞–ª–∞–≤—Ä –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –Ω–∞—É–∫\n\n\n–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ\n–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–≥—Ä–æ-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç\n\n\n–û–ø–∏—Å–∞–Ω–∏–µ\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n\n\n–§–æ—Ä–º–∞ –æ–±—É—á–µ–Ω–∏—è\n–û—á–Ω–∞—è"
  },
  {
    "objectID": "about-ru.html#–∏—é–Ω—å-2023-–¥–µ–∫–∞–±—Ä—å-2023",
    "href": "about-ru.html#–∏—é–Ω—å-2023-–¥–µ–∫–∞–±—Ä—å-2023",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "–ò—é–Ω—å 2023 ‚Äì –î–µ–∫–∞–±—Ä—å 2023",
    "text": "–ò—é–Ω—å 2023 ‚Äì –î–µ–∫–∞–±—Ä—å 2023\n\n\n\n–î–æ–ª–∂–Ω–æ—Å—Ç—å\n–≠–∫–æ–Ω–æ–º–∏—Å—Ç\n\n\n\n\n–ö–æ–º–ø–∞–Ω–∏—è\n¬´–ú–µ–ª–∏—Ç–æ–ø–æ–ª—å—Å–∫–∏–π –º–æ–ª–æ—á–Ω—ã–π –∑–∞–≤–æ–¥¬ª\n\n\n–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ\n–£–∫—Ä–∞–∏–Ω–∞, –ú–µ–ª–∏—Ç–æ–ø–æ–ª—å\n\n\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã\n~7 –º–µ—Å—è—Ü–µ–≤\n\n\n\n\n–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏\n–ö–æ–Ω—Ç—Ä–æ–ª—å —Å–∫–ª–∞–¥—Å–∫–∏—Ö –∑–∞–ø–∞—Å–æ–≤ –≥–æ—Ç–æ–≤–æ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º\n–†–∞—Å—á–µ—Ç —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–¥—É–∫—Ü–∏–∏\n–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Python, R –∏ SQL –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"
  },
  {
    "objectID": "about-ru.html#–Ω–æ—è–±—Ä—å-2020-–æ–∫—Ç—è–±—Ä—å-2022",
    "href": "about-ru.html#–Ω–æ—è–±—Ä—å-2020-–æ–∫—Ç—è–±—Ä—å-2022",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "–ù–æ—è–±—Ä—å 2020 ‚Äì –û–∫—Ç—è–±—Ä—å 2022",
    "text": "–ù–æ—è–±—Ä—å 2020 ‚Äì –û–∫—Ç—è–±—Ä—å 2022\n\n\n\n–î–æ–ª–∂–Ω–æ—Å—Ç—å\n–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–∏—Å–∫–∞–º–∏\n\n\n\n\n–ö–æ–º–ø–∞–Ω–∏—è\n¬´Forward Bank LLC¬ª\n\n\n–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ\n–£–∫—Ä–∞–∏–Ω–∞, –ö–∏–µ–≤\n\n\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã\n~2 –≥–æ–¥–∞\n\n\n\n\n–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤ –ø–æ —Ä–∏—Å–∫–∞–º, –≤–∫–ª—é—á–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –≤—ã—è–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π\n–ö–æ–Ω—Ç—Ä–æ–ª—å –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —á–µ—Ä–Ω—ã–º —Å–ø–∏—Å–∫–∞–º, –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–∞—Ö BKI/PTI\n–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö (R/SQL)\n–í–Ω–µ–¥—Ä–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤\n–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü Oracle: —Å–æ–∑–¥–∞–Ω–∏–µ, –∏–∑–º–µ–Ω–µ–Ω–∏–µ, —É–¥–∞–ª–µ–Ω–∏–µ –∏ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö\n–û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –æ—à–∏–±–æ–∫, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö\n–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: –∞–≥—Ä–µ–≥–∞—Ü–∏—è, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ä–µ–∑–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º"
  },
  {
    "objectID": "about-ru.html#section-1",
    "href": "about-ru.html#section-1",
    "title": "–®–µ–≤—á–µ–Ω–∫–æ –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á",
    "section": "2016 - 2018",
    "text": "2016 - 2018\n\n\n\n–î–æ–ª–∂–Ω–æ—Å—Ç—å\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç\n\n\n\n\n–ö–æ–º–ø–∞–Ω–∏—è\nBand\n\n\n–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ\n–£–∫—Ä–∞–∏–Ω–∞, –ö–∏–µ–≤\n\n\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã\n~2 –≥–æ–¥–∞\n\n\n\n\n–£–¥–∞–ª—ë–Ω–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –¥–ª—è Windows –∏ Linux\n–ê—Ä–µ–Ω–¥–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ VPS (VDS) —Å–µ—Ä–≤–µ—Ä–∞–º–∏\n–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"
  },
  {
    "objectID": "about-no.html",
    "href": "about-no.html",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "",
    "text": "Oversette üåê\nüá¨üáß ¬¶ üá≥üá¥ ¬¶ üá∫üá¶ ¬¶ üá∑üá∫\n\n\n\n\n\n\n\n\nF√òDSELSDATO\n29.08.1997 (28 √•r)\n\n\nKJ√òNN\nMann\n\n\nSIVILSTAND\nSingel\n\n\nNASJONALITET\nUkraina\n\n\nBOSTED\nBj√∏rnafjorden, Norge\n\n\nUTDANNING\nH√∏yere utdanning\n\n\nJOBBS√òKING\nVurderer tilbud"
  },
  {
    "objectID": "about-no.html#section",
    "href": "about-no.html#section",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "2016 ‚Äì 2020",
    "text": "2016 ‚Äì 2020\n\n\n\nGrad og utdanningsretning\nBachelor Datavitenskap\n\n\nUtdannings Institusjon\nStatlig agro-teknologisk universitet\n\n\nBeskrivelse\nInformasjonteknologi\n\n\nForm av Trening\nHeltid"
  },
  {
    "objectID": "about-no.html#juni-2023-desember-2023",
    "href": "about-no.html#juni-2023-desember-2023",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "Juni 2023 ‚Äì Desember 2023",
    "text": "Juni 2023 ‚Äì Desember 2023\n\n\n\nJOBB TITEL\n√òkonom\n\n\n\n\nBEDRIFT\n¬´Melitopol melkefabrikken¬ª\n\n\nSTED\nUkraine, Melitopol\n\n\nERFARING ARBEID\n~7 m√•neder\n\n\n\n\nUtarbeidelse og oppdatering av selskapets balanseoversikt\nKontroll av lagerbeholdning for ferdigvarer og materiell\nAnalyse av salgsdata fordelt p√• butikker\nBeregning av produksjonskostnader\nAutomatisering og optimalisering av arbeidsprosesser ved bruk av Python, R og SQL for √• √∏ke effektiviteten"
  },
  {
    "objectID": "about-no.html#november-2020-oktober-2022",
    "href": "about-no.html#november-2020-oktober-2022",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "November 2020 ‚Äì Oktober 2022",
    "text": "November 2020 ‚Äì Oktober 2022\n\n\n\nJOBB TITEL\nSpesialist i risikostyring\n\n\n\n\nBEDRIFT\n¬´Forward Bank LLC¬ª\n\n\nSTED\nUkraine, Kyev\n\n\nERFARING ARBEID\n~2 √•r\n\n\n\n\nAnalytiske risikorapporter, overv√•king og avviksidentifisering\nKundefkontroll etter interne krav: sjekk mot svartelister, sjekk personer i BKI/PTI-databaser\nUtvikling og optimalisering av skript for automatisert datakontroll (R/SQL)\nImplementering av nye metrikker og indikatorer for risikovurdering\nAdministrasjon av Oracle-tabeller: opprettelse, endring, sletting, og sikring av dataintegritet\nRensing og klargj√∏ring av r√•data: fjerning av duplikater og feilaktige oppf√∏ringer, og standardisering av dataformat\nDatabehandling for analyse: aggregering, filtrering og utsnitt via n√∏kkelmetrikker"
  },
  {
    "objectID": "about-no.html#section-1",
    "href": "about-no.html#section-1",
    "title": "Shevchenko Vladimir Vladimirovich",
    "section": "2016 - 2018",
    "text": "2016 - 2018\n\n\n\nJOBB TITEL\nTeknisk spesialist\n\n\n\n\nBEDRIFT\nBand\n\n\nSTED\nUkraine, Kyev\n\n\nERFARING ARBEID\n~2 √•r\n\n\n\n\nFjernteknisk brukerst√∏tte\nInstallering og konfigurasjon av programvare for Windows og Linux\nLeie og drift av VPS (VDS) servere\nAutomatisering av arbeidsprosesser"
  }
]